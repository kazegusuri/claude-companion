import { ActionIcon, Stack, Tooltip } from "@mantine/core";
import { IconMessage, IconMessageDown, IconMessageOff } from "@tabler/icons-react";
import type React from "react";
import { useCallback, useEffect, useRef, useState } from "react";
import { ChatDisplay } from "../components/ChatDisplay";
import { MainLayout } from "../components/Layout/MainLayout";
import { Live2DModelViewer } from "../components/Live2DModelViewer";
import type { ChatMessage, ConnectionStatus } from "../services/WebSocketClient";
import { WebSocketAudioClient } from "../services/WebSocketClient";

type BubbleState = "right" | "bottom" | "hidden";

export const Dashboard: React.FC = () => {
  const [speechText, setSpeechText] = useState("éŸ³å£°ã‚’å¾…æ©Ÿä¸­...");
  const [bubbleState, setBubbleState] = useState<BubbleState>("bottom"); // åˆæœŸçŠ¶æ…‹ã§ä¸‹å´è¡¨ç¤º
  const [isAudioEnabled, setIsAudioEnabled] = useState(false);
  const [_connectionStatus, setConnectionStatus] = useState<ConnectionStatus>("disconnected");
  const [currentMessageId, setCurrentMessageId] = useState<string | null>(null);
  const [currentAudioData, setCurrentAudioData] = useState<string | undefined>(undefined);

  const wsClient = useRef<WebSocketAudioClient | null>(null);
  const audioQueue = useRef<ChatMessage[]>([]);
  const isProcessingQueue = useRef(false);

  // éŸ³å£°ã‚­ãƒ¥ãƒ¼ã‚’å‡¦ç†
  const processAudioQueue = useCallback(async () => {
    if (isProcessingQueue.current || audioQueue.current.length === 0) {
      return;
    }

    if (!isAudioEnabled) {
      audioQueue.current = [];
      setCurrentAudioData(undefined);
      return;
    }

    isProcessingQueue.current = true;
    const message = audioQueue.current[0];

    if (message?.audioData) {
      setCurrentMessageId(message?.id || null);
      // Live2DModelViewerã®speakãƒ¡ã‚½ãƒƒãƒ‰ã§å†ç”Ÿ
      setCurrentAudioData(message.audioData);
    } else {
      audioQueue.current.shift();
      isProcessingQueue.current = false;
    }
  }, [isAudioEnabled]);

  // WebSocketãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒãƒ³ãƒ‰ãƒ©ãƒ¼
  const handleWebSocketMessage = useCallback(
    (message: ChatMessage) => {
      // ãƒ†ã‚­ã‚¹ãƒˆã‚’æ›´æ–°ï¼ˆassistantãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®ã¿ï¼‰
      if (message.text && message.role === "assistant") {
        setSpeechText(message.text);
      }

      // éŸ³å£°ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹å ´åˆã¯ã‚­ãƒ¥ãƒ¼ã«è¿½åŠ 
      // Check for assistant messages with audio subtype or legacy audio type
      if (
        (message.type === "audio" ||
          (message.type === "assistant" && message.subType === "audio")) &&
        message.audioData &&
        isAudioEnabled
      ) {
        // æ—¢å­˜ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãŒã‚­ãƒ¥ãƒ¼ã«ãªã„ã‹ç¢ºèª
        if (!audioQueue.current.some((msg) => msg.id === message.id)) {
          audioQueue.current.push(message);
          // å„ªå…ˆåº¦ã§ã‚½ãƒ¼ãƒˆ
          audioQueue.current.sort((a, b) => b.priority - a.priority);
          // ã‚­ãƒ¥ãƒ¼ã®å‡¦ç†ã‚’é–‹å§‹
          processAudioQueue();
        }
      }
    },
    [isAudioEnabled, processAudioQueue],
  );

  // éŸ³å£°å†ç”Ÿçµ‚äº†æ™‚ã®å‡¦ç†
  const handleAudioEnd = useCallback(() => {
    // ã‚­ãƒ¥ãƒ¼ã‹ã‚‰å‰Šé™¤
    audioQueue.current.shift();
    setCurrentMessageId(null);
    setCurrentAudioData(undefined);
    isProcessingQueue.current = false;

    // æ¬¡ã®ã‚¢ã‚¤ãƒ†ãƒ ã‚’å‡¦ç†
    if (audioQueue.current.length > 0) {
      setTimeout(processAudioQueue, 100);
    }
  }, [processAudioQueue]);

  // WebSocketæ¥ç¶šã®åˆæœŸåŒ–
  useEffect(() => {
    // æ—¢å­˜ã®æ¥ç¶šã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
    if (wsClient.current) {
      wsClient.current.disconnect();
      wsClient.current = null;
    }

    // WebSocketã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’ä½œæˆ
    const wsUrl = import.meta.env.VITE_WS_URL || "ws://localhost:8080/ws/audio";
    wsClient.current = new WebSocketAudioClient(wsUrl, handleWebSocketMessage, setConnectionStatus);

    // WebSocketã«æ¥ç¶š
    wsClient.current.connect();

    // ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
    return () => {
      if (wsClient.current) {
        wsClient.current.disconnect();
        wsClient.current = null;
      }
    };
  }, [handleWebSocketMessage]);

  // éŸ³å£°ã®ãƒˆã‚°ãƒ«
  const handleToggleAudio = async () => {
    if (!isAudioEnabled) {
      setIsAudioEnabled(true);
    } else {
      setIsAudioEnabled(false);
      audioQueue.current = [];
      setCurrentMessageId(null);
      setCurrentAudioData(undefined);
    }
  };

  // 3æ®µéšãƒˆã‚°ãƒ«: å³å´ â†’ ä¸‹å´ â†’ éè¡¨ç¤º â†’ å³å´...
  const toggleBubble = () => {
    setBubbleState((prev) => {
      switch (prev) {
        case "right":
          return "bottom";
        case "bottom":
          return "hidden";
        case "hidden":
          return "right";
      }
    });
  };

  // ã‚¢ã‚¤ã‚³ãƒ³ã¨ãƒ„ãƒ¼ãƒ«ãƒãƒƒãƒ—ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’æ±ºå®š
  const getIconAndTooltip = () => {
    switch (bubbleState) {
      case "right":
        return {
          icon: <IconMessage size={18} />,
          tooltip: "å¹ãå‡ºã—ï¼šå³å´è¡¨ç¤ºä¸­ â†’ ã‚¯ãƒªãƒƒã‚¯ã§ä¸‹å´ã¸",
        };
      case "bottom":
        return {
          icon: <IconMessageDown size={18} />,
          tooltip: "å¹ãå‡ºã—ï¼šä¸‹å´è¡¨ç¤ºä¸­ â†’ ã‚¯ãƒªãƒƒã‚¯ã§éè¡¨ç¤º",
        };
      case "hidden":
        return {
          icon: <IconMessageOff size={18} />,
          tooltip: "å¹ãå‡ºã—ï¼šéè¡¨ç¤º â†’ ã‚¯ãƒªãƒƒã‚¯ã§å³å´ã¸",
        };
    }
  };

  const { icon, tooltip } = getIconAndTooltip();

  return (
    <MainLayout
      modelComponent={
        <div
          style={{
            flex: 1,
            minHeight: 0,
            display: "flex",
            flexDirection: "row",
            justifyContent: "space-between",
            padding: "10px",
          }}
        >
          <div
            style={{
              flex: 1,
              height: "100%",
              minHeight: 0,
              display: "flex",
              alignItems: "center",
              justifyContent: "center",
            }}
          >
            <Live2DModelViewer
              speechText={speechText}
              isSpeaking={bubbleState !== "hidden"}
              bubbleSide={bubbleState === "hidden" ? "bottom" : bubbleState}
              useCard={true}
              cardTitle="ASSISTANT"
              {...(currentAudioData !== undefined && { audioData: currentAudioData })}
              onAudioEnd={handleAudioEnd}
            />
          </div>
          <div
            style={{
              minHeight: 0,
              display: "flex",
              flexDirection: "column",
              alignItems: "flex-end",
              justifyContent: "flex-end",
              paddingBottom: "5px",
            }}
          >
            <Stack gap="xs">
              <Tooltip label={isAudioEnabled ? "éŸ³å£°ON" : "éŸ³å£°OFF"} position="top" withArrow>
                <ActionIcon
                  onClick={handleToggleAudio}
                  size="sm"
                  radius="xl"
                  variant={isAudioEnabled ? "filled" : "light"}
                  color={isAudioEnabled ? "green" : "gray"}
                  style={{
                    zIndex: 1001,
                  }}
                >
                  {isAudioEnabled ? "ğŸ”Š" : "ğŸ”‡"}
                </ActionIcon>
              </Tooltip>
              <Tooltip label={tooltip} position="top" withArrow>
                <ActionIcon
                  onClick={toggleBubble}
                  size="sm"
                  radius="xl"
                  variant="filled"
                  style={{
                    zIndex: 1001,
                  }}
                >
                  {icon}
                </ActionIcon>
              </Tooltip>
            </Stack>
          </div>
        </div>
      }
      scheduleComponent={null}
      textComponent={null}
      chatComponent={<ChatDisplay currentPlayingMessageId={currentMessageId} />}
    />
  );
};
